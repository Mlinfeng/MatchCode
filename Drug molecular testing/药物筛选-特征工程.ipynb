{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a99d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0a507",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"ai4scup-cns_v3/mol_train.csv\")\n",
    "train_data.columns=[\"SMILES\", \"TARGET\"]\n",
    "train_data.to_csv(\"./ai4scup-cns_v3/mol_train.csv\", index=False)\n",
    "test_data = pd.read_csv(\"./ai4scup-cns_v3/mol_test.csv\")\n",
    "test_data.columns=[\"SMILES\", \"TARGET\"]\n",
    "test_data.to_csv(\"./ai4scup-cns_v3/mol_test.csv\", index=False)\n",
    "\n",
    "print(\"------ train data ------\")\n",
    "print(train_data)\n",
    "print(\"POSITIVE:\", sum(train_data[\"TARGET\"]==1))\n",
    "print(\"NEGETIVE:\", sum(train_data[\"TARGET\"]==0))\n",
    "\n",
    "print(\"------ test  data ------\")\n",
    "print(test_data)\n",
    "print(\"POSITIVE:\", sum(test_data[\"TARGET\"]==1))\n",
    "print(\"NEGETIVE:\", sum(test_data[\"TARGET\"]==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bff4f1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "def calculate_1dqsar_repr(smiles):\n",
    "    # 从 SMILES 字符串创建分子对象\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # 计算分子的分子量\n",
    "    mol_weight = Descriptors.MolWt(mol)\n",
    "    # 计算分子的 LogP 值\n",
    "    log_p = Descriptors.MolLogP(mol)\n",
    "    # 计算分子中的氢键供体数量\n",
    "    num_h_donors = Descriptors.NumHDonors(mol)\n",
    "    # 计算分子中的氢键受体数量\n",
    "    num_h_acceptors = Descriptors.NumHAcceptors(mol)\n",
    "    # 计算分子的表面积极性\n",
    "    tpsa = Descriptors.TPSA(mol)\n",
    "    # 计算分子中的可旋转键数量\n",
    "    num_rotatable_bonds = Descriptors.NumRotatableBonds(mol)\n",
    "    # 计算分子中的芳香环数量\n",
    "    num_aromatic_rings = Descriptors.NumAromaticRings(mol)\n",
    "    # 计算分子中的脂环数量\n",
    "    num_aliphatic_rings = Descriptors.NumAliphaticRings(mol)\n",
    "    # 计算分子中的饱和环数量\n",
    "    num_saturated_rings = Descriptors.NumSaturatedRings(mol)\n",
    "    # 计算分子中的杂原子数量\n",
    "    num_heteroatoms = Descriptors.NumHeteroatoms(mol)\n",
    "    # 计算分子中的价电子数量\n",
    "    num_valence_electrons = Descriptors.NumValenceElectrons(mol)\n",
    "    # 计算分子中的自由基电子数量\n",
    "    num_radical_electrons = Descriptors.NumRadicalElectrons(mol)\n",
    "    # 计算分子的 QED 值\n",
    "    qed = Descriptors.qed(mol)\n",
    "    # 返回所有计算出的属性值\n",
    "    return [mol_weight, log_p, num_h_donors, num_h_acceptors, tpsa, num_rotatable_bonds, num_aromatic_rings,\n",
    "            num_aliphatic_rings, num_saturated_rings, num_heteroatoms, num_valence_electrons, num_radical_electrons,qed]\n",
    "\n",
    "\n",
    "train_data[\"1dqsar_mr\"] = train_data[\"SMILES\"].apply(calculate_1dqsar_repr)\n",
    "test_data[\"1dqsar_mr\"] = test_data[\"SMILES\"].apply(calculate_1dqsar_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d15bf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(train_data[\"1dqsar_mr\"][0])\n",
    "print(\"一维的特征有%d个\"%len(train_data[\"1dqsar_mr\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838e6c7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def calculate_2dqsar_repr(smiles):    \n",
    "    # 将smiles字符串转换为rdkit的分子对象\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # 计算Morgan指纹（半径为3，长度为1024位）\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 3, nBits=1024)\n",
    "    # 返回numpy数组格式的指纹\n",
    "    return np.array(fp)\n",
    "\n",
    "train_data[\"2dqsar_mr\"] = train_data[\"SMILES\"].apply(calculate_2dqsar_repr) \n",
    "test_data[\"2dqsar_mr\"] = test_data[\"SMILES\"].apply(calculate_2dqsar_repr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aab687",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(train_data[\"2dqsar_mr\"][0].tolist())\n",
    "print(\"二维的特征有%d个\"%len(train_data[\"2dqsar_mr\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304699d3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from rdkit.Chem import rdPartialCharges\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def calculate_3dqsar_repr(SMILES, max_atoms=100, three_d=False):\n",
    "    mol = Chem.MolFromSmiles(SMILES)  # 从SMILES表示创建分子对象\n",
    "    mol = Chem.AddHs(mol)  # 添加氢原子\n",
    "    if three_d:\n",
    "        AllChem.EmbedMolecule(mol, AllChem.ETKDG())  # 计算3D坐标\n",
    "    else:\n",
    "        AllChem.Compute2DCoords(mol)  # 计算2D坐标\n",
    "    natoms = mol.GetNumAtoms()  # 获取原子数量\n",
    "    rdPartialCharges.ComputeGasteigerCharges(mol)  # 计算分子的Gasteiger电荷\n",
    "    charges = np.array([float(atom.GetProp(\"_GasteigerCharge\")) for atom in mol.GetAtoms()])  # 获取电荷值\n",
    "    coords = mol.GetConformer().GetPositions()  # 获取原子坐标\n",
    "    coulomb_matrix = np.zeros((max_atoms, max_atoms))  # 初始化库仑矩阵\n",
    "    n = min(max_atoms, natoms)\n",
    "    for i in range(n):  # 遍历原子\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                coulomb_matrix[i, j] = 0.5 * charges[i] ** 2\n",
    "            if i != j:\n",
    "                delta = np.linalg.norm(coords[i] - coords[j])  # 计算原子间距离\n",
    "                if delta != 0:\n",
    "                    coulomb_matrix[i, j] = charges[i] * charges[j] / delta  # 计算库仑矩阵的元素值\n",
    "                    coulomb_matrix[j, i] = coulomb_matrix[i, j]\n",
    "    coulomb_matrix = np.where(np.isinf(coulomb_matrix), 0, coulomb_matrix)  # 处理无穷大值\n",
    "    coulomb_matrix = np.where(np.isnan(coulomb_matrix), 0, coulomb_matrix)  # 处理NaN值\n",
    "    return coulomb_matrix.reshape(max_atoms*max_atoms).tolist()  # 将库仑矩阵转换为列表并返回\n",
    "\n",
    "\n",
    "train_data[\"3dqsar_mr\"] = train_data[\"SMILES\"].apply(calculate_3dqsar_repr) \n",
    "test_data[\"3dqsar_mr\"] = test_data[\"SMILES\"].apply(calculate_3dqsar_repr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a8caa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"三维的特征有%d个\"%len(train_data[\"3dqsar_mr\"][0]))\n",
    "print(train_data[\"3dqsar_mr\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data\n",
    "\n",
    "\n",
    "# ### 下面是特征融合，将一维、二维、三维进行了特征融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2e570",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 将这些列合并为特征矩阵X,处理train_data\n",
    "# 使用values属性可以直接获得每列中的数据，返回结果为numpy数组\n",
    "X_1dqsar = np.stack(train_data[\"1dqsar_mr\"].values)\n",
    "X_2dqsar = np.stack(train_data[\"2dqsar_mr\"].values)\n",
    "X_3dqsar = np.stack(train_data[\"3dqsar_mr\"].values)\n",
    "# 水平堆叠这些特征向量，形成一个更宽的特征矩阵\n",
    "X = np.hstack((X_1dqsar, X_2dqsar, X_3dqsar))\n",
    "# 对特征进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "print(\"X_train shape:\" ,X_train.shape)\n",
    "\n",
    "y_train = np.array(train_data[\"TARGET\"].values.tolist())\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# 处理test_data\n",
    "# 获取特征向量\n",
    "X_1dqsar_test = np.stack(test_data[\"1dqsar_mr\"].values)\n",
    "X_2dqsar_test = np.stack(test_data[\"2dqsar_mr\"].values)\n",
    "X_3dqsar_test = np.stack(test_data[\"3dqsar_mr\"].values)\n",
    "\n",
    "# 将特征向量合并为特征矩阵X_test，与训练数据相对应\n",
    "X_test = np.hstack((X_1dqsar_test, X_2dqsar_test, X_3dqsar_test))\n",
    "# 使用相同的scaler可以确保测试数据的标准化方式与训练数据一致\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"X_test_scaled shape:\" ,X_test.shape)\n",
    "y_test = np.array(test_data[\"TARGET\"].values.tolist())\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749d1d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# 特征选择: 使用随机森林重要性评分进行特征选择\n",
    "select = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
    "X_train_selected = select.fit_transform(X_train, y_train)\n",
    "\n",
    "# 降维: 使用PCA进一步减少维度到合理数量\n",
    "pca = PCA(n_components=0.85)  # 保留85%的方差\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "\n",
    "# 创建机器学习算法模型: 随机森林分类器\n",
    "clf = RandomForestClassifier(n_estimators=800)\n",
    "\n",
    "# # 训练模型\n",
    "# clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# 特征选择和降维可以与模型训练结合成一个pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', select),\n",
    "    ('dimension_reduction', pca),\n",
    "    ('classification', clf)\n",
    "])\n",
    "\n",
    "# 划分训练数据和测试数据\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 训练pipeline\n",
    "pipeline.fit(X_train_split, y_train_split)\n",
    "\n",
    "# 在测试集上评估模型\n",
    "y_pred = pipeline.predict(X_test_split)\n",
    "\n",
    "# 计算 F2 分数\n",
    "f2_score = fbeta_score(y_test_split, y_pred, beta=2)\n",
    "\n",
    "print(f\"F2 Score: {f2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964cbe6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
