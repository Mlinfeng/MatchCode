{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. 内容和目标 \n在本示例中，我们将介绍和演示以下内容:\n- Uni-Mol的主要特点 \n- Uni-Mol的分子、原子表示方法 \n- Uni-Mol的核心模块和相关参数 \n- 如何微调超参数（如学习率 learning rate）来训练模型 \n- 实际应用 ","metadata":{},"id":"bf6b1425-71e7-4d92-b342-40bc74729c50"},{"cell_type":"markdown","source":"## 2. 挂载数据集路径 \n本教学案例需要使用的数据，已通过Bohrium数据集功能共享给当前项目的用户。\n\n数据集的路径为","metadata":{},"id":"336ff67e-f394-48d2-9b65-16b6be2dae29"},{"cell_type":"code","source":"Dataset_Dir = '/bohr/data-ksoi/v1/data/' ","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"7b55f507-47a8-4800-a7c0-bd25e9c5413a"},{"cell_type":"markdown","source":"## 2.1 读取数据，并对数据进行拆分和初步的分析 \n【注】Uni-Mol进行Finetuning时，默认使用<i>5-Fold Cross Validation</i>的方式进行模型验证。 ","metadata":{},"id":"0c3833f8-0648-41ef-befa-41d770c08d73"},{"cell_type":"code","source":"import os \nimport pandas as pd\n\n# 读入数据 \ntrain_data_full = pd.read_csv(os.path.join(Dataset_Dir, 'mol_train.csv'))\ntrain_data_full.columns=[\"SMILES\", \"TARGET\"] \ntrain_data_full.to_csv(\"./mol_train_full.csv\", index=False) \n\ntrain_data_split = train_data_full[:500] \ntrain_data_split.columns=[\"SMILES\", \"TARGET\"]\ntrain_data_split.to_csv(\"./mol_train_split.csv\", index=False) \n\nvalid_data_split = train_data_full[500:] \nvalid_data_split.columns=[\"SMILES\", \"TARGET\"]\n\ndirectory = \"/data/UniMol_QSAR\"\n\n# 如果目录不存在，则创建它\nif not os.path.exists(directory):\n    os.makedirs(directory)\n\n\nvalid_data_split.to_csv(\"/data/UniMol_QSAR/mol_valid_split.csv\", index=False) \n\ntest_data = pd.read_csv(os.path.join(Dataset_Dir, 'mol_test.csv'))\ntest_data.columns=[\"SMILES\", \"TARGET\"]\ntest_data.to_csv(\"./mol_test.csv\", index=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"9aeb4d94-5e71-4bf4-bdc5-17c4a84da518"},{"cell_type":"markdown","source":"## 4. Uni-Mol的分子、原子表示方法 ","metadata":{},"id":"fddcdf6d-38e2-4be6-810a-4bad9327462b"},{"cell_type":"code","source":"# 导入Uni-Mol \nfrom unimol import UniMolRepr \nimport numpy as np \n\n# single smiles unimol representation\nclf = UniMolRepr(data_type='molecule', remove_hs=False) \n\nsmiles_list = train_data_split[\"SMILES\"].values.tolist()[:1] \n\nunimol_repr = clf.get_repr(smiles_list, return_atomic_reprs=True) \n\n# Uni-Mol分子表征, 使用cls token \nprint(np.array(unimol_repr['cls_repr']).shape) \nprint(np.array(unimol_repr['cls_repr'])) \n\n# Uni-Mol 原子级别表征，和rdkit Mol的原子顺序一致 \nprint(np.array(unimol_repr['atomic_reprs']).shape) \nprint(np.array(unimol_repr['atomic_reprs'])) ","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"2ee2ad83-376d-4974-9163-dfbaeb2dcd2d"},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.decomposition import PCA\n\nsmiles_list = valid_data_split[\"SMILES\"].values.tolist() \ny = valid_data_split[\"TARGET\"].values.tolist() \nrepr_dict = clf.get_repr(smiles_list)\nunimol_repr_list = np.array(repr_dict['cls_repr']) \n\npca = PCA(n_components=2) \nX_reduced = pca.fit_transform(unimol_repr_list) \n\n# 可视化\ncolors = ['r', 'g', 'b']\nmarkers = ['s', 'o', 'D']\nlabels = ['Target:0','Target:1']\n\nplt.figure(figsize=(8, 6))\n\nfor label, color, marker in zip(np.unique(y), colors, markers):\n    plt.scatter(X_reduced[y == label, 0], \n                X_reduced[y == label, 1], \n                c=color, \n                marker=marker, \n                label=labels[label],\n                edgecolors='black')\n\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.legend(loc='best')\nplt.title('Unimol Repr')\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"1713713b-1ddd-4be8-bea8-2237cbf5679e"},{"cell_type":"markdown","source":"## 5. Uni-Mol的核心模块和相关参数 ","metadata":{},"id":"7f89e06b-bd2b-4213-a6b4-65db2e0d7d25"},{"cell_type":"code","source":"# 导入Uni-Mol \nfrom unimol import MolTrain, MolPredict ","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"6d8ee359-7c5c-4f82-9906-33d3e0e08f01"},{"cell_type":"markdown","source":"### 5.1. “Moltrain”模块的参数说明\n#### task：选择对应的任务，目前支持五种任务类型：\n- classification: 0/1分类\n- regression: 回归\n- multiclass: 多分类\n- multilabel_classification: 多标签0/1分类\n- multilabel_regression: 多标签回归\n#### metrics: 对应需要模型优化的指标，传入的metrics可以用逗号分隔，为空默认，目前支持的指标如下：\n- classification: auc,auprc,log_loss,f1_score, mcc,recall,precision,cohen_kappa;\n- regression: mae, mse, rmse, r2, spearmanr;\n- multiclass: log_loss, acc;\n- multilabel_classification: log_loss, acc, auprc, cohen_kappa;\n- multilabel_regression: mse, mae, rmse, r2;\n#### data_type：输入的数据类型，目前仅支持molecule，后续会开放protein, crystal等更多数据源 \n#### split：unimol 默认采用5-Fold Cross Validation验证方式，划分方式支持random和按照scaffold划分 \n#### save_path：当前的任务路径，默认会覆盖文件 \n#### epochs, learning_rate, batch_size, early_stopping：unimol训练时开放的超参数","metadata":{},"id":"47a8406c-dd05-485b-a8cb-4b73102026eb"},{"cell_type":"markdown","source":"### 5.2. 超参数调整（Hyperparameter Finetuning） \n超参数是机器学习模型中的参数，其值不能通过训练数据集直接学习得到，而是需要人为设定。例如，学习率、批处理大小、训练周期数、神经网络的层数和每层的节点数等都是典型的超参数。超参数调整的目的是为了找到一组能使模型在测试数据集上表现最好的超参数。因为超参数的值直接影响到模型的训练效果和预测性能，所以合理的调整超参数对于获得高质量的机器学习模型是非常重要的。\n\n### 5.3. Metrics \n#### 5.3.1. F2-score \n`F2-score` 是 `F1-beta` 取 $beta = 2$ 时的特殊形式。  `F1-beta` 允许我们调整精确率（Precision）和召回率（Recall）之间的权重，其一般形式如下：\n\n$$F1-beta = (1 + beta^2) * (Precision * Recall) / (beta^2 * Precision + Recall)$$\n\n在本次赛事中，我们更在意模型的召回率，取 $beta = 2$。此时我们得到 `F2-score`，`F2-score` 的计算公式为：\n\n$$F2-score = 5 * (Precision * Recall) / (4 * Precision + Recall)$$\n\n其中，Precision = 真正例（TP）/（真正例（TP）+假正例（FP）），Recall = 真正例（TP）/（真正例（TP）+假负例（FN））。\nTP（True Positive）表示实际为正例且预测为正例的样本数；TN（True Negative）表示实际为负例且预测为负例的样本数；FP（False Positive）表示实际为负例但预测为正例的样本数；FN（False Negative）表示实际为正例但预测为负例的样本数。\n\n最终排行榜展示结果只保留 `F2-score` 的四位小数，并根据F2-score来评估模型的好坏：\n\n- 接近1的F2-score表示模型性能很好，意味着模型在正确预测正例方面做得很好，同时尽量减少了假负例（即避免将实际为正的样本预测为负）。\n\n- 接近0的F2-score表示模型性能很差，意味着模型在正确预测正例方面做得很差，同时产生了很多假负例。\n\n#### 5.3.2. AUC-ROC \n- AUC-ROC是一种用于评估分类模型性能的指标，全称为Area Under the Receiver Operating Characteristic Curve（接收者操作特征曲线下的面积）。在这里，ROC曲线是一个描绘了真正类率（True Positive Rate, TPR）和假正类率（False Positive Rate, FPR）在不同分类阈值下变化情况的曲线。\n- 真正类率（TPR）也叫敏感性，它度量的是所有实际为正的样本中，被正确地判断为正的比例。TPR = TP / (TP + FN)，其中TP是真正类的数量，FN是假负类的数量。假正类率（FPR）度量的是所有实际为负的样本中，被错误地判断为正的比例。FPR = FP / (FP + TN)，其中FP是假正类的数量，TN是真负类的数量。\n- AUC值即为ROC曲线下的面积，它反映了模型在任意分类阈值下的整体性能。AUC值在0.5到1之间，值越接近1，模型的性能越好。一般来说，如果模型的AUC值大于0.5，那么模型就比随机猜测好；如果AUC值等于0.5，那么模型的性能就等同于随机猜测；如果AUC值小于0.5，那么模型的性能就比随机猜测差。\n- AUC-ROC值的优点在于，它不依赖于特定的分类阈值，因此对于评估模型的整体性能非常有用，尤其是在正负样本不均衡的情况下。\n\n【注】本次赛题采用 `F2-score` 作为评价指标。","metadata":{},"id":"f753e198-f7c0-4de9-9867-6df0c95abb09"},{"cell_type":"code","source":"# 使用全量数据进行Fine-Tuneing，并使用Cross-Validation的方法验证模型的性能 \nfrom sklearn.metrics import roc_auc_score, roc_curve, fbeta_score # 导入sklearn.metrics以输出模型的ROC-AUC和F2-score\n\nthreshold = 0.5 \n\ntrain_full_results = {} \n\nfont = {'family': 'serif',\n        'color':  'black',\n        'weight': 'normal',\n        'size': 8} \n\nlr_ft = [1e-5, 1e-4, 1e-3] # 学习率\nfor i in range(len(lr_ft)): # 循环输入每个学习率   \n    clf = MolTrain(task='classification', \n                   data_type='molecule',\n                   epochs=20,\n                   learning_rate=lr_ft[i],\n                   batch_size=16,\n                   early_stopping=5,\n                   metrics='auc',\n                   split='random',\n                   save_path='./full_learning_rate_'+str(lr_ft[i]),\n                  )\n    \n    clf.fit(\"./mol_train_full.csv\") # 训练模型 \n    \n    cv_results = pd.DataFrame({'pred':clf.cv_pred.flatten(), \n                           'SMILES':train_data_full[\"SMILES\"], \n                           'Target_BBB':train_data_full[\"TARGET\"]}) \n     \n    auc = roc_auc_score(cv_results.Target_BBB, cv_results.pred) \n    fpr, tpr, _ = roc_curve(cv_results.Target_BBB, cv_results.pred) \n    f2_score = fbeta_score(\n        cv_results.Target_BBB, \n        [1 if p > threshold else 0 for p in cv_results.pred], \n        beta=2\n    )\n    \n    train_full_results[f\"Full Learning Rate: {lr_ft[i]}\"] = {\"AUC\": auc, \"FPR\": fpr, \"TPR\": tpr, \"F2_Score\": f2_score} \n    print(f\"[Learning Rate: {lr_ft[i]}]\\tAUC:{auc:.4f}\\tF2_Score:{f2_score:.4f}\") \n\nsorted_train_full_results = sorted(train_full_results.items(), key=lambda x: x[1][\"F2_Score\"], reverse=True) # 根据AUC对结果进行排序\n\n# 绘制ROC曲线\nplt.figure(figsize=(10, 6), dpi=150)\nplt.title(\"ROC Curves\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\n\nfor name, result in sorted_train_full_results:\n    if name.startswith(\"Full Learning Rate\"):\n        plt.plot(result[\"FPR\"], result[\"TPR\"], label=f\"{name} (AUC:{result['AUC']:.4f} F2_Score:{result['F2_Score']:.4f})\")\n\nplt.legend(loc=\"lower right\") \nplt.title(\"Train_Full_Model\", fontdict=font) \nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"03a1ee52-5f7c-4f22-8fd8-b88025d83bdb"},{"cell_type":"code","source":"# # 使用手动拆分的数据train_data_split进行Fine-Tuneing \n# lr_ft = [1e-5, 1e-4, 1e-3] # 学习率\n# for i in range(len(lr_ft)): # 循环输入每个学习率   \n#     clf = MolTrain(task='classification', \n#                    data_type='molecule',\n#                    epochs=20,\n#                    learning_rate=lr_ft[i],\n#                    batch_size=16,\n#                    early_stopping=5,\n#                    metrics='none',\n#                    split='random',\n#                    save_path='./split_learning_rate_'+str(lr_ft[i]),\n#                   )\n    \n#     clf.fit(\"./mol_train_split.csv\") # 训练模型 ","metadata":{},"execution_count":null,"outputs":[],"id":"69c730a7-055b-47d0-96ea-f4203f01dd55"},{"cell_type":"markdown","source":"### 5.4. “MolPredict”模块的参数说明 \n#### load_model:训练好的模型路径 ","metadata":{},"id":"3b6d5432-3711-4d4d-ba2f-d2f172685975"},{"cell_type":"code","source":"# 使用手动拆分的数据valid_data_split验证模型的性能 \n# threshold = 0.5\n\n# valid_split_results = {} \n\n# lr_ft = [1e-5, 1e-4, 1e-3] # 学习率\n# for i in range(len(lr_ft)): # 循环输入每个学习率 \n#     valid_pred_model = MolPredict(load_model='./split_learning_rate_'+str(lr_ft[i])) # 载入不同学习率下的模型 \n    \n#     valid_pred = valid_pred_model.predict(\"./mol_valid_split.csv\") #对测试数据进行预测 \n    \n#     valid_results = pd.DataFrame({'pred':valid_pred.reshape(-1), \n#                            'SMILES':valid_data_split[\"SMILES\"], \n#                            'Target_BBB':valid_data_split[\"TARGET\"]}) \n    \n#     auc = roc_auc_score(valid_results.Target_BBB, valid_results.pred) \n#     fpr, tpr, _ = roc_curve(valid_results.Target_BBB, valid_results.pred) \n#     f2_score = fbeta_score(\n#         valid_results.Target_BBB, \n#         [1 if p > threshold else 0 for p in valid_results.pred], \n#         beta=2\n#     )\n    \n#     valid_split_results[f\"Split Learning Rate: {lr_ft[i]}\"] = {\"AUC\": auc, \"FPR\": fpr, \"TPR\": tpr, \"F2_Score\": f2_score} \n#     print(f\"[Learning Rate: {lr_ft[i]}]\\tAUC:{auc:.4f}\\tF2_Score:{f2_score:.4f}\") \n\n# sorted_valid_split_results = sorted(valid_split_results.items(), key=lambda x: x[1][\"F2_Score\"], reverse=True) # 根据AUC对结果进行排序\n\n# # 绘制ROC曲线\n# plt.figure(figsize=(10, 6), dpi=200)\n# plt.title(\"ROC Curves\")\n# plt.xlabel(\"False Positive Rate\")\n# plt.ylabel(\"True Positive Rate\")\n\n# for name, result in sorted_valid_split_results:\n#     if name.startswith(\"Split Learning Rate\"):\n#         plt.plot(result[\"FPR\"], result[\"TPR\"], label=f\"{name} (AUC:{result['AUC']:.4f} F2_Score:{result['F2_Score']:.4f})\")\n\n# plt.legend(loc=\"lower right\") \n# plt.title(\"Validation_Split_Model\", fontdict=font) \n# plt.show() ","metadata":{},"execution_count":null,"outputs":[],"id":"7c3cbf30-b974-4d46-9498-ec6d8ef7f1b9"},{"cell_type":"markdown","source":"## 6. 使用效果最好的模型对测试数据进行预测 ","metadata":{},"id":"5e2bef29-9c05-41a4-a16b-f965900b89cd"},{"cell_type":"code","source":"# 使用全量数据训练的模型在对test数据进行预测 \nthreshold = 0.5\n\ntest_full_pred_model = MolPredict(load_model='./full_learning_rate_'+str(1e-4)) # 载入不同学习率下的模型 \n\ntest_smi = {\"SMILES\": test_data[\"SMILES\"].values.tolist()} \n\ntest_full_pred = test_full_pred_model.predict(test_smi[\"SMILES\"]) #对测试数据进行预测 \n    \ntest_full_results = pd.DataFrame({'pred':test_full_pred.reshape(-1), \n                                  'SMILES':test_data[\"SMILES\"]}) \n\ntest_full_results[\"TARGET\"] = [1 if x > threshold else 0 for x in test_full_results[\"pred\"].values.tolist()] \n\ntest_full_results[[\"SMILES\", \"TARGET\"]].to_csv('submission.csv', index=False, header=True) ","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"e12f1b3b-fa06-4f40-b82b-5a215faae274"},{"cell_type":"code","source":"# 使用手动拆分的数据训练的模型对test数据进行预测 \n# test_split_pred_model = MolPredict(load_model='./split_learning_rate_'+str(1e-3)) # 载入不同学习率下的模型 \n\n# test_split_pred = test_split_pred_model.predict(test_smi[\"SMILES\"]) #对测试数据进行预测 \n    \n# test_split_results = pd.DataFrame({'pred':test_split_pred.reshape(-1), \n#                                    'SMILES':test_data[\"SMILES\"]}) \n\n# test_split_results[\"TARGET\"] = [1 if x > threshold else 0 for x in test_split_pred[\"pred\"].values.tolist()] \n\n# test_split_results[[\"SMILES\", \"TARGET\"]].to_csv('./Split_Model_Submission.csv', index=False, header=True) ","metadata":{},"execution_count":null,"outputs":[],"id":"1e37a7de-8eca-4aeb-8237-c2f72f3a4c05"}]}